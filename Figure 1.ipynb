{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to generate figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and definitions\n",
    "import Utils\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from pandas.plotting import scatter_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from ML import *\n",
    "\n",
    "ph_dir = \"/home/pau/Data/BioB/\"\n",
    "gn_dir = '/home/data/biobank/'\n",
    "force_recreation=False\n",
    "#Load Data \n",
    "x_train, x_test, y_train, y_test = Utils.load_data(ph_dir, gn_dir, trait=\"height\", th=65.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(x_train,y_train,model,k=0,v=0):\n",
    "    early_stopping = EarlyStopping(patience=4, verbose=0)\n",
    "    reduce_lr = ReduceLROnPlateau(factor=0.2, verbose=0, patience=2, min_lr=1e-5)\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    "    model.fit(x_train, y_train, callbacks=callbacks, epochs=150, validation_split=0.2, verbose=v)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load / Train models\n",
    "if os.path.exists('models/Gwas_10k/mlp1.hd5') and not force_recreation:\n",
    "    m1 = load_model('models/Gwas_10k/mlp1.hd5')\n",
    "else:\n",
    "    m1 = model1(x_train)\n",
    "    m1 = Train(x_train,y_train,m1)\n",
    "    m1.save('models/Gwas_10k/mlp1.hd5')\n",
    "    \n",
    "if os.path.exists('models/Gwas_10k/mlp2.hd5') and not force_recreation:\n",
    "    m2 = load_model('models/Gwas_10k/mlp2.hd5')\n",
    "else:\n",
    "    m2 = ridge(x_train)\n",
    "    m2 = Train(x_train,y_train,r)\n",
    "    m2.save('models/Gwas_10k/mlp2.hd5') \n",
    "\n",
    "if os.path.exists('models/Gwas_10k/lasso.hd5') and not force_recreation:\n",
    "    l = load_model('models/Gwas_10k/lasso.hd5')\n",
    "else:\n",
    "    l = lasso(x_train)\n",
    "    l = Train(x_train,y_train,l)\n",
    "    m1.save('models/Gwas_10k/lasso.hd5')    \n",
    "    \n",
    "if os.path.exists('models/Gwas_10k/ridge.hd5') and not force_recreation:\n",
    "    r = load_model('models/Gwas_10k/ridge.hd5')\n",
    "else:\n",
    "    r = ridge(x_train)\n",
    "    r = Train(x_train,y_train,r)\n",
    "    m1.save('models/Gwas_10k/ridge.hd5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-score feature importance and hidden representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zImp(model):\n",
    "    nf = model.input_shape[1]\n",
    "    x = np.eye(nf)\n",
    "    y = model.predict(x).ravel()\n",
    "    y = (y - y.mean())/y.std()\n",
    "    y = np.abs(y)\n",
    "    y = y / y.sum()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getH1(model,x):\n",
    "    m = Model(model.layers[0].input,model.layers[0].output)\n",
    "    return m.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute importances of features for different methods\n",
    "imp = zImp(m1)\n",
    "imp2 = zImp(m2)\n",
    "wl = np.abs(l.get_weights()[0])\n",
    "wl = wl/wl.sum()\n",
    "wr = np.abs(mr.get_weights()[0])\n",
    "wr = wr/wr.sum()\n",
    "m = np.asarray([wl.ravel()*100,wr.ravel()*100,imp.ravel()*100,imp2.ravel()*100])\n",
    "m = m.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce Varible importance scatter plot\n",
    "axes = scatter_matrix(df, alpha=0.5,figsize=(10, 10), diagonal='kde')\n",
    "corr = df.corr().as_matrix()\n",
    "for i, j in zip(*plt.np.triu_indices_from(axes, k=1)):\n",
    "    axes[i, j].annotate(\"%.3f\" %corr[i,j], (0.8, 0.8), xycoords='axes fraction', ha='center', va='center')\n",
    "plt.suptitle('Varible importance of different models: GWAS 10k')\n",
    "plt.savefig('imp_10k.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer representation mlp1\n",
    "h1_mlp1 = getH1(m1,x_train)\n",
    "idx= sum(h1_mlp1>0).argsort()[::-1]\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
    "z1=ax1.hist(h1_mlp1[:,idx[0]]*50,50,density=True)\n",
    "ax1.set_title('1st')\n",
    "ax1.set_xlabel('activation value')\n",
    "z2=ax2.hist(h1_mlp1[:,idx[1]]*50,50,density=True)\n",
    "ax2.set_title('2nd')\n",
    "ax2.set_xlabel('activation value')\n",
    "z3=ax3.hist(h1_mlp1[:,idx[2]]*50,50,density=True)\n",
    "ax3.set_title('3rd')\n",
    "ax3.set_xlabel('activation value')\n",
    "f.suptitle(\"Most active neurons 1st layer MLP1\")\n",
    "f.savefig('plots/mlp1_1st_10k.png',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer representation mlp1\n",
    "h1_mlp2=getH1(m2,x_train)\n",
    "idx= sum(h1_mlp2>0).argsort()[::-1]\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
    "a1=ax1.hist(h1_mlp2[:,idx[0]],50,density=True)\n",
    "ax1.set_title('1st')\n",
    "ax1.set_xlabel('activation value')\n",
    "a2=ax2.hist(h1_mlp2[:,idx[1]],50,density=True)\n",
    "ax2.set_title('2nd')\n",
    "ax2.set_xlabel('activation value')\n",
    "a3=ax3.hist(h1_mlp2[:,idx[2]],50,density=True)\n",
    "ax3.set_title('3rd')\n",
    "ax3.set_xlabel('activation value')\n",
    "f.suptitle(\"Most active neurons 1st layer mlp2\")\n",
    "f.savefig('plots/mlp2_1st_10k.png',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
